{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db0c288e",
   "metadata": {},
   "source": [
    "# Carbon emissions of __remotely__ executed code\n",
    "\n",
    "As we can't measure the carbon footprint generated by remotely executed code via an API request, the package API Emissions Tracker was developed to estimate it. Check out the [GitHub repository](https://github.com/borisruf/api_emissions_tracker) for more details.\n",
    "\n",
    "### First steps\n",
    "Let's start with installing the packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c2e148",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install api_emissions_tracker==0.0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dee794",
   "metadata": {},
   "source": [
    "For demonstration purposes you can also uses the Python library [Stub AI](https://github.com/borisruf/stub_ai/) which mimics the API requests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54f0b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install stub_ai==0.0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18627628",
   "metadata": {},
   "source": [
    "Import the StubAzureOpenAI class to simulate requests to the Azure OpenAI API. Also import the APIEmissionsTracker class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d0b9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stub_ai import StubAzureOpenAI\n",
    "from api_emissions_tracker import APIEmissionsTracker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4fa124",
   "metadata": {},
   "source": [
    "Specify the model you want to test. No need to worry about the endpoint and credentials as we use a mocked environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea446ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_ENDPOINT = \"[YOUR_AZURE_ENDPOINT]\"\n",
    "OPENAI_MODEL = \"gpt-35-turbo\"   # specify a supported model from the list: gpt-35-turbo, gpt-4, gpt-4o, gpt-4o-mini\n",
    "OPENAI_API_KEY = \"[YOUR_OPENAI_API_KEY]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b116a1d",
   "metadata": {},
   "source": [
    "The emission factors can be checked, changed and extended in [emission_factors.json](https://github.com/borisruf/api_emissions_tracker/blob/main/api_emissions_tracker/emission_factors.json). They can also get overwritten and enhanced as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bb936d",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_emission_factors = {\n",
    "  \"gpt-35-turbo\": {\n",
    "    \"per_completion_token\": 0.001,\n",
    "    \"per_prompt_token\": 0.002,\n",
    "    \"reference_url\": \"https://my.own.source\"\n",
    "  },\n",
    "  \"my-model\": {\n",
    "    \"per_completion_token\": 0.00051,\n",
    "    \"per_prompt_token\": 0.00051,\n",
    "    \"reference_url\": \"https://my.own.source2\"\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc775b02",
   "metadata": {},
   "source": [
    "Start the tracking:\n",
    "\n",
    "_*note that you can also write the log in a file by addind the parameter \"write_log_file\" into the APIEmissionsTracker object and set it to \"True\"_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b8f52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = APIEmissionsTracker(write_log_file=True, emission_factors=custom_emission_factors)\n",
    "tracker.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e63f256",
   "metadata": {},
   "source": [
    "Make the API request. The syntax of StubMockAzureOpenAI follows [AzureOpenAI](https://github.com/openai/openai-python?tab=readme-ov-fil#microsoft-azure-openai). For supported prompts, check the [StubAI documentation](https://github.com/borisruf/stub_ai/tree/main)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524a6083",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = StubAzureOpenAI(azure_endpoint=AZURE_ENDPOINT, api_key=OPENAI_API_KEY)\n",
    "response = client.chat.completions.create(model=OPENAI_MODEL, messages=[{\"role\": \"system\", \"content\": \"What is the origin of the Olympic Games?\"}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ca4875",
   "metadata": {},
   "source": [
    "Print the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23a716a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.choices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96def6cb",
   "metadata": {},
   "source": [
    "Print the total emissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927871a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6f94e7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# A quick look at the carbon emissions of a token\n",
    "We have been working on estimating the carbon emissions of LLMs, in particular SecureGPT.  \n",
    "The estimates were based on HuggingFace's [LLM Perf-Leaderboard](https://huggingface.co/spaces/optimum/llm-perf-leaderboard), which provides data on the energy consumption required to process open-source model tokens.\n",
    "\n",
    "Using this method, we estimated that a token sent or generated by GPT-3.5 consumes an average of 0.00000762501875 kWh, and therefore emits [2.46 mg CO2e](https://borisruf.github.io/carbon-footprint-modeling-tool/index.html?id=gpt-ruf-mortas-token&emission_type=co2e) if the service is located on the West side of the USA.\n",
    "\n",
    "One way of reducing LLM energy consumption is to reduce the number of tokens in, and particularly out.  \n",
    "For example, by fine-tuning the model to obtain short, structured responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877b9d73",
   "metadata": {},
   "source": [
    "### View your carbon footprint scenarios with transparency\n",
    "The [Carbon footprint modeling tool](https://github.com/borisruf/carbon-footprint-modeling-tool) makes it easy to create, share and compare emission scenarios. Its purpose is to improve data quality and transparency in the field of carbon footprint quantification.\n",
    "\n",
    "#### Example scenarios:\n",
    "- [Streaming a 30-minute video [IEA updated, UK]](https://borisruf.github.io/carbon-footprint-modeling-tool/?id=scenario-8f35af7c-ee5b-42aa-b538-371b126b3d24) ([source](https://github.com/borisruf/carbon-footprint-modeling-tool/blob/main/scenarios/scenario-8f35af7c-ee5b-42aa-b538-371b126b3d24.json))\n",
    "- [Streaming a 30-minute video [IEA updated, Laptop and HD]](https://borisruf.github.io/carbon-footprint-modeling-tool/?id=scenario-725b3ff2-294b-4cfc-81a3-fc460ee61fdc) ([source](https://github.com/borisruf/carbon-footprint-modeling-tool/blob/main/scenarios/scenario-725b3ff2-294b-4cfc-81a3-fc460ee61fdc.json))\n",
    "- [Singapore (SIN) to Paris (CDG) round-trip](https://borisruf.github.io/carbon-footprint-modeling-tool/?id=scenario-0065da59-7785-4eed-8a11-c73b70cf798e)  ([source](https://github.com/borisruf/carbon-footprint-modeling-tool/blob/main/scenarios/scenario-0065da59-7785-4eed-8a11-c73b70cf798e.json))\n",
    "- [Nested sample of personal carbon footprint](https://borisruf.github.io/carbon-footprint-modeling-tool/?id=scenario-265789b8-d7d1-442f-ba79-e627b9226c86) ([source](https://github.com/borisruf/carbon-footprint-modeling-tool/blob/main/scenarios/scenario-265789b8-d7d1-442f-ba79-e627b9226c86.json))\n",
    "- [Cargo ship emissions portfolio](https://borisruf.github.io/carbon-footprint-modeling-tool/?id=scenario-d9de099f-a408-4526-aec2-f781c9972b42) ([source](https://github.com/borisruf/carbon-footprint-modeling-tool/blob/main/scenarios/scenario-d9de099f-a408-4526-aec2-f781c9972b42.json))\n",
    "- [Monthly operation of ChatGPT](https://borisruf.github.io/carbon-footprint-modeling-tool/benchmark.html?ids%5B%5D=gpt-ruf-mortas-1&ids%5B%5D=gpt-pointon-1&ids%5B%5D=gpt-selvan-1b&ids%5B%5D=gpt-vries-1&factor=590000000&title=Monthly%20carbon%20footprint%20of%20ChatGPT%20(several%20scenarios))\n",
    "\n",
    "#### Tools:\n",
    "A way to simply create scenarios for your LLM applications is to use the [AI Emissions Scenario Generator](https://borisruf.github.io/carbon-footprint-modeling-tool/ai-scenarios.html).  \n",
    "Simply fill your model(s), the location(s) and number of tokens processed. Then compare your GHG emissions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444991fb",
   "metadata": {},
   "source": [
    "# Recommendations on technological tools and choice of infrastructure\n",
    "## Tools and technologies\n",
    "### Use of energy-efficient tools\n",
    "Use tools and libraries that are designed to optimize computing resources and GPU (NumPy, TensorFlow, PyTorch, ...).\n",
    "\n",
    "Follow green coding good practices. For example: https://medium.com/@moustaphadaka\n",
    "\n",
    "Quantization is a process that reduces the precision of numerical data. In power efficiency, it's used to lower the bit precision in digital systems and machine learning models. This leads to less memory usage, faster computations, and reduced power consumption. However, it can introduce errors, so a balance between efficiency and accuracy is needed.\n",
    "\n",
    "### Choose the right model\n",
    "Instead of re-training a model, a similar to the one you want to create may already exist. You can finetune a model close to yours to suit your needs.\n",
    "\n",
    "Choose the right model for your needs:\n",
    "- choose a specialized model rather than a general one,\n",
    "- balance between necessary accuracy, size and energy performance.\n",
    "\n",
    "For LLMs inference, reduce the number of tokens in the instruction prompt and in the answers\n",
    "\n",
    "### Tools for quantifying environmental impact\n",
    "Measure and estimate the environmental impact of projects with adapted libraries. Other tools, such as the Green Algorithms Project, offer methods and best practices for designing more environmentally-friendly algorithms.\n",
    "\n",
    "*References:* \n",
    "- https://codecarbon.io/ (Python)\n",
    "- https://github.com/lfwa/carbontracker (Python)\n",
    "- https://developers.thegreenwebfoundation.org/co2js/overview/ (JavaScript)\n",
    "- https://calculator.green-algorithms.org/ (Server)\n",
    "- https://borisruf.github.io/carbon-footprint-modeling-tool/ai-scenarios.html (\n",
    "\n",
    "## Choice of infrastructure\n",
    "### Use of green infrastructures\n",
    "Opt for data centers powered by renewable energies and committed to a good ESG policy.\n",
    "\n",
    "### Choose low carbon intensity location\n",
    "- Norway: x kg CO2e/kWh\n",
    "- Sweden: x kg CO2e/kWh\n",
    "- France: x kg CO2e/kWh\n",
    "- Switzerland: x kg CO2e/kWh\n",
    "- Finland: x kg CO2e/kWh\n",
    "- Denmark: x kg CO2e/kWh\n",
    "- Brazil: x kg CO2e/kWh\n",
    "- Canada: x kg CO2e/kWh\n",
    "- Belgium: x kg CO2e/kWh\n",
    "- Austria: x kg CO2e/kWh\n",
    "- Spain: x kg CO2e/kWh\n",
    "- Ireland: x kg CO2e/kWh\n",
    "\n",
    "*source: https://www.iea.org/data-and-statistics/data-product/emissions-factors-2022*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
