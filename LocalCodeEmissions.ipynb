{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cc5018",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install codecarbon==2.7.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4b53dc",
   "metadata": {},
   "source": [
    "# The Environmental Impact of Software Engineering\n",
    "\n",
    "## Resource Consumption in Software Development\n",
    "\n",
    "Modern software development, particularly in AI and machine learning, requires substantial computational resources. This has significant environmental implications:\n",
    "\n",
    "- Training complex models often requires millions of iterations and large datasets.\n",
    "- Computation times can extend to tens or hundreds of hours on high-performance hardware.\n",
    "- The energy demand for these processes contributes to a considerable environmental footprint.\n",
    "- Additional environmental costs come from cooling IT equipment and data centers.\n",
    "\n",
    "## Hardware Considerations: CPUs, GPUs and Environmental Impact\n",
    "\n",
    "Central Processing Unit (CPUs) and now Graphics Processing Units (GPUs) have become crucial in software development, especially for AI and machine learning tasks. Their use comes with environmental considerations:\n",
    "\n",
    "- GPUs typically consume more energy than traditional CPUs due to their architecture.\n",
    "- Heat generation from GPUs necessitates extensive cooling systems, further increasing energy and water consumption.\n",
    "  - Example: AWS data centers use an average of 0.19 L of water per kWh for cooling.\n",
    "- The lifecycle of hardwares also contributes to environmental impact:\n",
    "  - Production requires rare and precious materials, with significant ecological ramifications.\n",
    "  - Limited lifespan and frequent upgrades generate hard-to-recycle electronic waste.\n",
    "\n",
    "## Comparative Environmental Impact\n",
    "\n",
    "To put the environmental impact in perspective:\n",
    "\n",
    "| Item | CO2e Emissions |\n",
    "|------|----------------|\n",
    "| [NVIDIA A100 GPU manufacture](https://dl.acm.org/doi/pdf/10.1145/3581784.3607035) | Up to 25 kg |\n",
    "| [CPU manufacture](https://api.boavizta.org/docs#/component/cpu_impact_bottom_up_v1_component_cpu_get) | 19 kg (range: 10-80 kg) |\n",
    "| [1 HP ProBook laptop manufacturing](https://h20195.www2.hp.com/v2/GetDocument.aspx?docname=c08546039) | 112.5 kg |\n",
    "| [3 000 km car journey](https://impactco2.fr/outils/transport) | 155 kg |\n",
    "| [1 hot shower in France](https://borisruf.github.io/carbon-footprint-modeling-tool/?id=scenario-1hot-shower) | 162 g |\n",
    "| [1 kg chicken meat production](https://openknowledge.fao.org/server/api/core/bitstreams/121cc613-3d0f-431c-b083-cc2031dd8826/content) | 1 kg |\n",
    "| [1 kg beef meat production](https://openknowledge.fao.org/server/api/core/bitstreams/121cc613-3d0f-431c-b083-cc2031dd8826/content) | 30 kg |\n",
    "\n",
    "## Implications for Software Engineers\n",
    "\n",
    "As software engineers, we should consider:\n",
    "\n",
    "1. Optimizing code for efficiency to reduce computational requirements.\n",
    "2. Designing software architectures that minimize resource usage.\n",
    "3. Exploring green computing practices in our development processes.\n",
    "4. Considering the environmental impact when choosing development tools and platforms.\n",
    "5. Advocating for sustainable practices in software development within our organizations.\n",
    "\n",
    "By being aware of these environmental impacts, we can work towards more sustainable software engineering practices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd31764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Image processing\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import multiprocessing\n",
    "\n",
    "# Database query\n",
    "import os\n",
    "import sqlite3\n",
    "\n",
    "# Energy consumption\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c51ee7f",
   "metadata": {},
   "source": [
    "# First example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4d7f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def while_loop(n):\n",
    "    i = 0\n",
    "    s = 0\n",
    "    while i < n:\n",
    "        s += 1\n",
    "        i += 1\n",
    "    return s\n",
    "    \n",
    "def for_loop(n):\n",
    "    s = 0\n",
    "    for i in range(n):\n",
    "        s += 1\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b88771",
   "metadata": {},
   "outputs": [],
   "source": [
    "numb = 100000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773a2ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_while = time.time()\n",
    "\n",
    "while_loop(numb)\n",
    "\n",
    "end_time_while = time.time()\n",
    "time_while = end_time_while - start_time_while\n",
    "print(f\"{time_while} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f17efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_for = time.time()\n",
    "\n",
    "for_loop(numb)\n",
    "\n",
    "end_time_for = time.time()\n",
    "time_for = end_time_for - start_time_for\n",
    "print(f\"{time_for} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349c4cae",
   "metadata": {},
   "source": [
    "A for loop may be more optimized and streamlined for repetitive tasks with a known number of iterations, allowing for better resource management and potentially lower power consumption. While loops, on the other hand, may require additional instructions to evaluate the loop condition repeatedly, potentially resulting in higher power usage.\n",
    "\n",
    "# Carbon emissions of locally executed software code\n",
    "The Python package CodeCarbon is designed to measure the carbon footprint of executing code on a __local__ device. Check out the [documentation](https://mlco2.github.io/codecarbon/) for more details.\n",
    "\n",
    "### First steps with CodeCarbon\n",
    "Let's start with loading the package previously downloaded:  \n",
    "\n",
    "_Source: [CodeCarbon](https://mlco2.github.io/codecarbon/)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75c3a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from codecarbon import OfflineEmissionsTracker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011880ce",
   "metadata": {},
   "source": [
    "Start the tracker\n",
    "\n",
    "/!\\ If you use codecarbon version 2.6.0 or lower, it might raise an error:  \n",
    "_TypeError: BaseEmissionsTracker.\\_\\_init\\_\\_() got an unexpected keyword argument 'allow_multiple_runs'_  \n",
    "\n",
    "In this case, you need to remove the 'allow_multiple_runs=True' parameter of the OfflineEmissionsTracker.  \n",
    "This parameter was introduced to fix a [bug in version 2.7.0 and 2.7.1](https://github.com/huggingface/optimum-benchmark/issues/260)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e7e233",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker1 = OfflineEmissionsTracker(country_iso_code='ESP', allow_multiple_runs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bceac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker1.start()\n",
    "\n",
    "print(while_loop(numb))\n",
    "\n",
    "tracker1.stop()\n",
    "print(f\"Training time: {tracker1.final_emissions_data.duration:.2f} seconds\")\n",
    "print(f\"GHG emissions: {np.format_float_scientific(tracker1.final_emissions_data.emissions, precision=2)} kg CO2e\")\n",
    "print(f\"Electricity: {np.format_float_scientific(tracker1.final_emissions_data.energy_consumed, precision=2)} kWh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a71ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker2 = OfflineEmissionsTracker(country_iso_code='ESP', allow_multiple_runs=True)\n",
    "\n",
    "tracker2.start()\n",
    "\n",
    "print(for_loop(numb))\n",
    "\n",
    "tracker2.stop()\n",
    "print(f\"Training time: {tracker2.final_emissions_data.duration:.2f} seconds\")\n",
    "print(f\"GHG emissions: {np.format_float_scientific(tracker2.final_emissions_data.emissions, precision=2)} kg CO2e\")\n",
    "print(f\"Electricity: {np.format_float_scientific(tracker2.final_emissions_data.energy_consumed, precision=2)} kWh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433f6a87",
   "metadata": {},
   "source": [
    "# Use customed python decorator with CodeCarbon to assess any function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d90b05",
   "metadata": {},
   "source": [
    "Tracking a function with the codecarbon decorator saves the data in an emissions.csv file in the project root.  \n",
    "You can customize your decorator to use different tracking parameters and display different metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98f4fc3",
   "metadata": {},
   "source": [
    "### CodeCarbon custom decorator parameters\n",
    "**tracking_mode**: machine (default): entire machine ; process: try to isolate the process\n",
    "\n",
    "**pue**: 1 (default) ; Old data-centers have a PUE up to 2.2, where new green one could be as low as 1.1.  \n",
    "Power usage effectiveness (PUE) is a metric used to measure the energy efficiency of a computer data center. It is the ratio of how much energy is used by the computing equipment in contrast to cooling and other overhead that supports the equipment.\n",
    "\n",
    "**gpu_ids**: None (default) ; User-specified known GPU ids to track.\n",
    "\n",
    "**measure_power_secs**: 15 (default) ; Interval (in seconds) to measure hardware power usage. The smaller it is, the more precise the measure is, but the more resources it requires =(\n",
    "\n",
    "**log_level**: Global codecarbon log level (by order of verbosity): “debug”, “info” (defaults), “warning”,\n",
    "“error”, or “critical”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4da26d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_emissions(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        tracker = OfflineEmissionsTracker(country_iso_code='ESP', tracking_mode='machine', log_level='critical', allow_multiple_runs=True)\n",
    "        tracker.start()\n",
    "\n",
    "        result = func(*args, **kwargs)\n",
    "\n",
    "        tracker.stop()\n",
    "        print(f\"\\nTraining time: {tracker.final_emissions_data.duration:.4f} seconds\")\n",
    "        print(f\"GHG emissions: {np.format_float_scientific(tracker.final_emissions_data.emissions, precision=2)} kg CO2e\")\n",
    "        print(f\"Electricity: {np.format_float_scientific(tracker.final_emissions_data.energy_consumed, precision=2)} kWh\\n\")\n",
    "\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5a7d26",
   "metadata": {},
   "source": [
    "### Now assess carbon emissions with your custom decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7cff0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@track_emissions\n",
    "def while_loop(n):\n",
    "    i = 0\n",
    "    s = 0\n",
    "    while i < n:\n",
    "        s += 1\n",
    "        i += 1\n",
    "    return s\n",
    "\n",
    "@track_emissions\n",
    "def for_loop(n):\n",
    "    s = 0\n",
    "    for i in range(n):\n",
    "        s += 1\n",
    "    return s\n",
    "\n",
    "print(while_loop(numb))\n",
    "print(for_loop(numb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df99283",
   "metadata": {},
   "outputs": [],
   "source": [
    "@track_emissions\n",
    "def sum_range(n):\n",
    "    return sum(range(n))\n",
    "\n",
    "@track_emissions\n",
    "def sum_numpy(n):\n",
    "    return np.sum(np.arange(n))\n",
    "\n",
    "@track_emissions\n",
    "def sum_math(n):\n",
    "    return (n * (n-1)) // 2\n",
    "\n",
    "print(\"Sum range:\")\n",
    "sum_range(numb)\n",
    "print(\"\\nSum numpy:\")\n",
    "sum_numpy(numb)\n",
    "print(\"\\nSum math:\")\n",
    "sum_math(numb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03a2792",
   "metadata": {},
   "source": [
    "# Software engineer example: Efficient Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c33990e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a synthetic dataset\n",
    "np.random.seed(18)\n",
    "X = 2 * np.random.rand(10000000, 1)\n",
    "y = 4 + 3 * X + np.random.randn(10000000, 1)\n",
    "\n",
    "# Division of the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bb08ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(X, y):\n",
    "    # Simulate some data processing\n",
    "    result = np.dot(X.T, y)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84640be",
   "metadata": {},
   "outputs": [],
   "source": [
    "@track_emissions\n",
    "def non_optimized_process():\n",
    "    result = process_data(X_train, y_train)\n",
    "    print(f\"Result shape: {result.shape}\")\n",
    "    print(f\"Result: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9610f9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@track_emissions\n",
    "def optimized_process():\n",
    "    batch_size = 50000\n",
    "    result = np.zeros((X_train.shape[1], y_train.shape[1]))\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        end = i + batch_size\n",
    "        result += process_data(X_train[i:end], y_train[i:end])\n",
    "    print(f\"Result shape: {result.shape}\")\n",
    "    print(f\"Result: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faba718",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_optimized_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a373df8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_process()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcfa950",
   "metadata": {},
   "source": [
    "<ins>Optimization Strategies:</ins>\n",
    "\n",
    "- **Batch Processing**: Instead of processing all data at once, we use small batches. This is more efficient in terms of memory management and resource consumption.  \n",
    "_Source: [Batch Processing: The Engine of Efficiency Behind the Scene](https://medium.com/@hayesha1744/batch-processing-the-engine-of-efficiency-behind-the-scene-511ac7536b3d)_\n",
    "- **Reduce Redundancy**: Batch processing can lead to less overall processing time and energy consumption, depending on the context and available resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cc0d81",
   "metadata": {},
   "source": [
    "# Optimizing Image Processing Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f734ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageProcessor:\n",
    "    def __init__(self, kernel_size=15):\n",
    "        self.kernel_size = kernel_size\n",
    "        # Creating the Gaussian kernel once\n",
    "        self.kernel = self._create_gaussian_kernel()\n",
    "        \n",
    "    def _create_gaussian_kernel(self):\n",
    "        \"\"\"Creates an optimized Gaussian kernel\"\"\"\n",
    "        x, y = np.meshgrid(np.linspace(-2, 2, self.kernel_size), \n",
    "                          np.linspace(-2, 2, self.kernel_size))\n",
    "        d = np.sqrt(x*x + y*y)\n",
    "        kernel = np.exp(-(d**2 / (2.0 * 2.0)))\n",
    "        return (kernel / kernel.sum()).astype(np.float32)\n",
    "\n",
    "    def process_original(self, image_array):\n",
    "        \"\"\"Original method not optimized for comparison\"\"\"\n",
    "        start_time = time.time()\n",
    "        result = np.zeros_like(image_array)\n",
    "        \n",
    "        for i in range(3):\n",
    "            temp = image_array[:,:,i].astype(np.float32)\n",
    "            for _ in range(5):\n",
    "                temp = cv2.filter2D(temp, -1, self.kernel)\n",
    "            result[:,:,i] = temp\n",
    "            \n",
    "        return result, time.time() - start_time\n",
    "\n",
    "    def _process_channel(self, channel):\n",
    "        \"\"\"Processes a single image channel\"\"\"\n",
    "        result = channel.astype(np.float32)\n",
    "        for _ in range(5):\n",
    "            result = cv2.filter2D(result, -1, self.kernel)\n",
    "        return result\n",
    "\n",
    "    def process_parallel(self, image_array):\n",
    "        \"\"\"Optimized version with multi-threading\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Channel separation\n",
    "        channels = [image_array[:,:,i] for i in range(3)]\n",
    "        \n",
    "        # Parallel channel processing\n",
    "        with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "            processed_channels = list(executor.map(self._process_channel, channels))\n",
    "            \n",
    "        # Image reconstruction\n",
    "        result = np.dstack(processed_channels).astype(np.uint8)\n",
    "        \n",
    "        return result, time.time() - start_time\n",
    "\n",
    "    def process_opencv(self, image_array):\n",
    "        \"\"\"OpenCV-only version for maximum performance\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Conversion to float32\n",
    "        image = image_array.astype(np.float32)\n",
    "        \n",
    "        # Applying convolutions with OpenCV\n",
    "        for _ in range(5):\n",
    "            image = cv2.filter2D(image, -1, self.kernel)\n",
    "            \n",
    "        # Conversion to uint8\n",
    "        result = np.clip(image, 0, 255).astype(np.uint8)\n",
    "        return result, time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9402ab58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_all_methods(image_path):\n",
    "    \"\"\"Compare all treatment methods\"\"\"\n",
    "    # Image loading\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Impossible to load the image: {image_path}\")\n",
    "    \n",
    "    processor = ImageProcessor()\n",
    "    results = {}\n",
    "    \n",
    "    print(\"Benchmarking in progress...\")\n",
    "    \n",
    "    # Testing each method\n",
    "    print(\"1. Original method test...\")\n",
    "    _, time_original = processor.process_original(img.copy())\n",
    "    results['Original'] = time_original\n",
    "    \n",
    "    print(\"2. Parallel method test...\")\n",
    "    _, time_parallel = processor.process_parallel(img.copy())\n",
    "    results['Parallel'] = time_parallel\n",
    "    \n",
    "    print(\"3. OpenCV method test...\")\n",
    "    _, time_opencv = processor.process_opencv(img.copy())\n",
    "    results['OpenCV'] = time_opencv\n",
    "    \n",
    "    # Results display\n",
    "    print(\"\\nBenchmark results:\")\n",
    "    print(\"-\" * 40)\n",
    "    for method, duration in results.items():\n",
    "        print(f\"{method:15} : {duration:.3f} secondes\")\n",
    "    \n",
    "    speedup = time_original/min(time_parallel, time_opencv)\n",
    "    print(f\"\\nMaximum acceleration: {speedup:.2f}x\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example of use\n",
    "benchmark_all_methods(\"images/im1.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40616886",
   "metadata": {},
   "source": [
    "<ins>Optimization Strategies:</ins>\n",
    "    \n",
    "- **Use Efficient Libraries:** Leverage optimized libraries like OpenCV or Pillow for image processing tasks.\n",
    "- **Resize Images:** Process smaller images when possible to reduce computational load.\n",
    "- **Caching:** Implement caching mechanisms to avoid redundant processing of the same images.\n",
    "- **Parallel Processing:** Utilize multi-threading for processing multiple images simultaneously.  \n",
    "_Source: [Energy Efficiency in High-Performance Computing: Balancing Speed and Sustainability](https://developer.nvidia.com/blog/energy-efficiency-in-high-performance-computing-balancing-speed-and-sustainability/)_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3eb763a",
   "metadata": {},
   "source": [
    "# Optimizing Database Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15550174",
   "metadata": {},
   "source": [
    "For all systems working with a database, performance is strongly impacted by the database’s performance and the quality of the network.\n",
    "\n",
    "While having an excellent network can improve system performance, adopting practices to enhance database processing performance is an essential ally.\n",
    "\n",
    "Among the performance improvement practices, we can mention adding indexes to the database, regular database maintenance, and query optimization.\n",
    "\n",
    "Tools exist to propose database optimization approaches, index creations to be done, following the analysis of queries that the tool sees passing through its query plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f837c292",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'Car_Database - Copie.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dd7632",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(db_name):\n",
    "    print(f\"Le fichier {db_name} n'a pas été trouvé dans le répertoire courant.\")\n",
    "    exit()\n",
    "\n",
    "conn = sqlite3.connect(db_name)\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efb5e0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = [row[0] for row in cursor.fetchall()]\n",
    "\n",
    "# Explore each table\n",
    "for table in tables:\n",
    "    print(f\"\\nTable '{table}':\")\n",
    "\n",
    "    cursor.execute(f\"PRAGMA table_info({table});\")\n",
    "    columns = [col[1] for col in cursor.fetchall()]\n",
    "    print(\"Columns:\", \", \".join(columns))\n",
    "    \n",
    "    cursor.execute(f\"SELECT COUNT(*) FROM {table}\")\n",
    "    lenght = cursor.fetchall()[0][0]\n",
    "    print(f\"Number of lines: {lenght}\")\n",
    "\n",
    "    # Get head of each table\n",
    "    cursor.execute(f\"SELECT * FROM {table} LIMIT 5;\")\n",
    "    rows = cursor.fetchall()\n",
    "    print(\"\\nFirst lines :\")\n",
    "    for row in rows:\n",
    "        print(row)\n",
    "        pass  \n",
    "    print('\\n#######################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9598660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = cursor.execute(\"\"\"\n",
    "SELECT c.customer_id, c.first_name, c.last_name, COUNT(cv.option_set_id) AS nombre_d_options\n",
    "FROM Customers c\n",
    "JOIN Customer_Ownership co ON c.customer_id = co.customer_id\n",
    "JOIN Car_Vins cv ON co.vin = cv.vin\n",
    "JOIN Car_Options copt ON cv.option_set_id = copt.option_set_id\n",
    "GROUP BY c.customer_id, c.first_name, c.last_name;\n",
    "\"\"\")\n",
    "time1 = time.time()\n",
    "print(res1.fetchall())\n",
    "print(f\"Time: {time.time() - time1} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef198dcf",
   "metadata": {},
   "source": [
    "## Optimization with indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8642329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List modes de paiement\n",
    "cursor.execute(\"\"\"\n",
    "CREATE INDEX customer_options_index ON Car_Vins (vin, option_set_id);\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53efaba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = cursor.execute(\"\"\"\n",
    "SELECT c.customer_id, c.first_name, c.last_name, COUNT(cv.option_set_id) AS nombre_d_options\n",
    "FROM Customers c\n",
    "JOIN Customer_Ownership co ON c.customer_id = co.customer_id\n",
    "JOIN Car_Vins cv ON co.vin = cv.vin\n",
    "JOIN Car_Options copt ON cv.option_set_id = copt.option_set_id\n",
    "GROUP BY c.customer_id, c.first_name, c.last_name;\n",
    "\"\"\")\n",
    "time2 = time.time()\n",
    "print(res2.fetchall())\n",
    "print(f\"Time: {time.time() - time2} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce77dcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close database connexion\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8254f41c",
   "metadata": {},
   "source": [
    "- **Indexing:** Properly index tables to improve query performance.  \n",
    "_Source: [Green Coding 2/7: Principles of Sustainable Data Management](https://medium.com/just-tech-it-now/green-coding-2-8-principles-of-sustainable-data-management-29edf3cac561#aa5a)_\n",
    "- **Query Optimization:** Write efficient queries that minimize data scans.\n",
    "- **Database Schema Design:** Design an efficient schema, including appropriate normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8d74ce",
   "metadata": {},
   "source": [
    "# General Optimization Strategies\n",
    "- **Code Profiling:** Use profiling tools to identify performance bottlenecks.\n",
    "- **Algorithmic Efficiency:** Choose and implement efficient algorithms for your tasks.\n",
    "- **Parallel Processing:** Utilize multi-threading or distributed computing when appropriate.\n",
    "- **Memory Management:** Optimize memory usage to reduce overall resource consumption.\n",
    "- **Caching:** Implement caching strategies to avoid redundant computations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856cc910",
   "metadata": {},
   "source": [
    "# Language selection\n",
    "**C/C++:** These are statically-typed, compiled languages. They are known for their efficiency and performance. Since they are compiled languages, the code is translated into machine code before it's run, which results in faster execution. However, they require more manual memory management, which can be a source of errors if not handled properly.\n",
    "\n",
    "**Java:** Java is a statically-typed, interpreted language. It uses a Just-In-Time (JIT) compiler to convert bytecode into machine code during runtime, which makes it faster than pure interpretation. Java also has automatic memory management (garbage collection), which can sometimes result in performance overhead but eliminates the risk of memory leaks.\n",
    "\n",
    "**Python:** Python is a dynamically-typed, interpreted language. It is known for its simplicity and readability, but its performance is generally slower compared to C/C++ and Java due to its interpretation at runtime. However, Python also has Just-In-Time compilation through libraries like PyPy and Numba, which can significantly speed up execution for certain types of computations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29824f2c",
   "metadata": {},
   "source": [
    "# Evaluate the environmental impact of one of your projects!\n",
    "You can use one of the libraries listed above in your projects, then try to reduce the environmental impact."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
